{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We start by fetching and saving cases for each year from 1990 to 2024 from the Oyez API.\n",
    "1. We set up a MongoDB client instance using credentials from environment variables and connects to the MongoDB database.\n",
    "2. For each year, it sends a GET request to the Oyez API to fetch cases for that year.\n",
    "3. If the request is successful, it inserts each case into the `cases` collection in the MongoDB database.\n",
    "4. If the request fails, it prints an error message with the status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MONGODB_USERNAME = os.getenv('MONGODB_USERNAME')\n",
    "MONGODB_PASSWORD = os.getenv('MONGODB_PASSWORD')\n",
    "MONGODB_HOST = os.getenv('MONGODB_HOST')\n",
    "MONGODB_DATABASE = os.getenv('MONGODB_DATABASE')\n",
    "\n",
    "mongo_uri = f\"mongodb+srv://{MONGODB_USERNAME}:{MONGODB_PASSWORD}@{MONGODB_HOST}/{MONGODB_DATABASE}?authSource=admin&replicaSet=db-mongo-graph-explorer\"\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[MONGODB_DATABASE]\n",
    "cases_collection = db.cases\n",
    "\n",
    "# Fetch and save cases for each year from 1990 to 2024\n",
    "for year in range(1990, 2025):\n",
    "    url = f\"https://api.oyez.org/cases?per_page=0&filter=term:{year}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        cases = response.json()\n",
    "        for case in cases:\n",
    "            cases_collection.insert_one(case)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for year {year}: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The cell below iterates over each document in the `cases` collection. \n",
    " 1. For each document, it fetches the `href` field and makes a GET request to that URL. \n",
    " 2. If the request is successful, it inserts the fetched data along with the original `href` and document ID into the `expanded_cases` collection. \n",
    " 3. If the request fails or an exception occurs, it prints an error message. \n",
    " 4. Finally, it prints \"Processing complete.\" when all documents have been processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "cases_collection = db.cases\n",
    "expanded_cases_collection = db.expanded_cases\n",
    "\n",
    "# Iterate over each document in the cases collection\n",
    "for doc in tqdm(cases_collection.find(), desc=\"Processing cases\"):\n",
    "    href = doc.get('href')\n",
    "    if href:\n",
    "        try:\n",
    "            response = requests.get(href)\n",
    "            if response.status_code == 200:\n",
    "                href_data = response.text\n",
    "                expanded_cases_collection.insert_one({\n",
    "                    'href': href,\n",
    "                    'data': href_data,\n",
    "                    'original_id': doc.get('_id')\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Failed to fetch href {href}: {response.status_code}\")\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Error fetching href {href}: {e}\")\n",
    "    else:\n",
    "        print(f\"No href found in document with ID: {doc.get('_id')}\")\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below iterates over each document in the `expanded_cases` collection.\n",
    "1. For each document, it retrieves the `data` and `href` fields.\n",
    "2. If `data` is present, it attempts to parse it as JSON and adds the `href` to the parsed data.\n",
    "3. The parsed data is then inserted into the `processed_cases` collection.\n",
    "4. If parsing fails, it prints an error message with the `href`.\n",
    "5. If `data` is not found, it prints a message indicating the missing data for the `href`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing data for href https://api.oyez.org/cases/2005/04-1034: Unterminated string starting at: line 1 column 32708 (char 32707)\n"
     ]
    }
   ],
   "source": [
    "expanded_cases_collection = db.expanded_cases\n",
    "processed_cases_collection = db.processed_cases\n",
    "\n",
    "for doc in expanded_cases_collection.find():\n",
    "    data = doc.get('data')\n",
    "    href = doc.get('href')\n",
    "    if data:\n",
    "        try:\n",
    "            parsed_data = json.loads(data)\n",
    "            parsed_data['href'] = href\n",
    "            processed_cases_collection.insert_one(parsed_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing data for href {href}: {e}\")\n",
    "    else:\n",
    "        print(f\"No data found in document with href {href}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fetch_and_convert_to_markdown` function: \n",
    "1. Takes a URL as input, fetches the HTML content from that URL, and converts specific parts of the HTML to markdown format. \n",
    "2. It first sends a GET request to the provided URL and checks if the request was successful.\n",
    "3. If successful, it parses the HTML content using BeautifulSoup and looks for a div with the class \"primary-content\".\n",
    "4. If such a div is found, it converts the content of the div to markdown by iterating over specific HTML elements (headers, paragraphs, lists) and formatting them accordingly.\n",
    "5. The resulting markdown string is then returned. If the div is not found or the request fails, appropriate error messages are returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_and_convert_to_markdown(url):\n",
    "    # Fetch the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the div with the class \"primary-content\"\n",
    "        primary_content_div = soup.find('div', class_='primary-content')\n",
    "\n",
    "        if primary_content_div:\n",
    "            # Convert the HTML to markdown\n",
    "            def html_to_markdown(soup):\n",
    "                markdown = \"\"\n",
    "                for element in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'ul', 'ol', 'li']):\n",
    "                    if element.name.startswith('h'):\n",
    "                        level = int(element.name[1])\n",
    "                        markdown += f\"{'#' * level} {element.get_text()}\\n\\n\"\n",
    "                    elif element.name == 'p':\n",
    "                        markdown += f\"{element.get_text()}\\n\\n\"\n",
    "                    elif element.name in ['ul', 'ol']:\n",
    "                        for li in element.find_all('li'):\n",
    "                            markdown += f\"- {li.get_text()}\\n\"\n",
    "                        markdown += \"\\n\"\n",
    "                return markdown\n",
    "\n",
    "            return html_to_markdown(primary_content_div)\n",
    "        else:\n",
    "            return \"No primary content found in the document.\"\n",
    "    else:\n",
    "        return f\"Failed to fetch the URL: {response.status_code}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell iterates over documents in the `cases_collection`.\n",
    "1. For each document, it retrieves the `written_opinion` field, which is expected to be a list.\n",
    "2. It then iterates over each opinion in the `written_opinion` list, extracting the `justia_opinion_url`, `id`, and `title`.\n",
    "3. If all three fields are present, it fetches the content from the `justia_opinion_url`, converts it to markdown, and inserts it into the `opinions_collection`.\n",
    "4. Finally, it closes the MongoDB connection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "cases_collection = db.processed_cases\n",
    "opinions_collection = db.opinions\n",
    "\n",
    "# Iterate over each document in the cases collection\n",
    "for doc in tqdm(cases_collection.find()):\n",
    "    written_opinions = doc.get('written_opinion', [])\n",
    "    if written_opinions is not None:\n",
    "        for opinion in written_opinions:\n",
    "            justia_opinion_url = opinion.get('justia_opinion_url')\n",
    "            justia_opinion_id = opinion.get('id')\n",
    "            title = opinion.get('title')\n",
    "\n",
    "            if justia_opinion_url and justia_opinion_id and title:\n",
    "                # Fetch the markdown content\n",
    "                markdown_content = fetch_and_convert_to_markdown(justia_opinion_url)\n",
    "\n",
    "                # Save the fetched document in the opinions collection\n",
    "                opinions_collection.insert_one({\n",
    "                    'id': justia_opinion_id,\n",
    "                    'case_id': doc.get('ID'),\n",
    "                    'title': title,\n",
    "                    'content': markdown_content\n",
    "                })\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
